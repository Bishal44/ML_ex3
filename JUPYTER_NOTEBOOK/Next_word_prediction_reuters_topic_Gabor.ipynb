{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50eb1355",
   "metadata": {
    "id": "50eb1355"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nXwmMiUHVmN1",
   "metadata": {
    "id": "nXwmMiUHVmN1"
   },
   "source": [
    "**Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f4c486",
   "metadata": {
    "id": "b0f4c486"
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for file in os.listdir(\"sample_data/\"): # original: \"reuters_data/\"\n",
    "    if file.endswith('.sgm'): # it is important for GoogleColab\n",
    "        filename = os.path.join(\"sample_data\", file) # original: \"reuters_data\"\n",
    "        f = open(filename, 'r', encoding='utf-8', errors='ignore')\n",
    "        dataFile = f.read().lower()\n",
    "        \n",
    "        soup = BeautifulSoup(dataFile, 'html.parser')\n",
    "\n",
    "        ## get all 'topic'\n",
    "        # topics = {topic.name for topic in soup.find_all()}\n",
    "  \n",
    "        ## iterate all 'topic'\n",
    "        # for topic in topics:\n",
    "          \n",
    "        ## find all element of 'topic'\n",
    "          # for i in soup.find_all('topic'):\n",
    "  \n",
    "        ## if tag has attribute of class\n",
    "            # if i.has_attr('trade'):\n",
    "  \n",
    "# We have selected the following 20 'TOPICS' out of 135:\n",
    "# that we want to use for our prediction exercise: 1.) \"trade\" 2.) \"earn\" 3.) \"grain\" 4.) \"money-fx\" 5.) \n",
    "# \"coffee\" 6.) \"gold\" 7.) \"acq\" 8.) \"wheat\" 9.) \"veg-oil\" 10.) \"nat-gas\" 11.) \"cooper\" 12.) \"ship\" 13.) \n",
    "# \"dlr\" 14.) \"crude\" 15.) \"interest\" 16.) \"meal-feed\" 17.) \"alum\" 18.) \"money-supply\" 19.) \"cocoa\" 20.) \"livestock\"\n",
    "        contents = soup.findAll('title')\n",
    "        \n",
    "        for content in contents:\n",
    "            documents.append(content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "jwFHnhJ6YrPG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwFHnhJ6YrPG",
    "outputId": "d769a4f3-c6cf-427b-a14c-8aff14712298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 9953\n"
     ]
    }
   ],
   "source": [
    "print('Number of documents: {}'.format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "BwkB00Xzx-vT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwkB00Xzx-vT",
    "outputId": "96174c3f-7547-410f-e863-1e685dd209ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 9599\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated strings from the list of strings\n",
    "documents = [i for n, i in enumerate(documents) if i not in documents[:n]]\n",
    "\n",
    "print('Number of documents: {}'.format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9549e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f9549e3",
    "outputId": "34adf071-e76d-4a8a-da33-599a658dc082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ibc coffee auctions to start soon - dauster',\n",
       " 'amca (ail) names new chairman',\n",
       " 'api oil inventory report to be issued tonight',\n",
       " 'soro group to limit fairchild <fen> stock buys',\n",
       " 'fed adds reserves via two-day repurchases',\n",
       " 'capital associates <caii.o> to trade on nasdaq',\n",
       " 'mint reviews offers on 3,701,000 lbs copper',\n",
       " 'ahed <ahm.to> may issue one mln shares',\n",
       " 'u.s. west <usw> introduces data network product',\n",
       " 'french winter cereal sowing seen little changed']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fRsdiodgY4er",
   "metadata": {
    "id": "fRsdiodgY4er"
   },
   "source": [
    "**Join the documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5894ab",
   "metadata": {
    "id": "9e5894ab"
   },
   "outputs": [],
   "source": [
    "data = \"\"\n",
    "for d in documents:\n",
    "    data += d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a635c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3a635c4",
    "outputId": "2f6d665d-70bb-408a-ead2-2c2cf4bc68ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 435763\n"
     ]
    }
   ],
   "source": [
    "print('Number of data: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffe6795",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ffe6795",
    "outputId": "5cd35f61-cdbd-4e69-9b9c-57b0e2a101e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 434881\n",
      "ibc coffee auctions to start soon - dausteramca (ail) names new chairmanapi oil inventory report to \n"
     ]
    }
   ],
   "source": [
    "# improve punctuation\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "print('Number of data: {}'.format(len(data)))\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CNRiSJsMtwQu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNRiSJsMtwQu",
    "outputId": "6041d359-b0ae-4595-b68e-1b311d10f968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ibc coffee auctions to start soon   dausteramca  ail  names new chairmanapi oil inventory report to \n"
     ]
    }
   ],
   "source": [
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "data = data.translate(translator)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225b3c6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "225b3c6b",
    "outputId": "1a2ff1ab-a9ae-4344-d847-44f658e0b0e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1570, 209, 1974, 1, 444]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded_data = tokenizer.texts_to_sequences([data])[0]\n",
    "print(len(encoded_data))\n",
    "encoded_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff5b658",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cff5b658",
    "outputId": "c03f23da-60ed-4603-cbea-8aff102dcbe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 17323\n"
     ]
    }
   ],
   "source": [
    "# determine the vocabulary size\n",
    "# unique_words = tokenizer.word_index\n",
    "unique_words = np.unique(encoded_data)\n",
    "vocab_size = len(unique_words) + 1  # 0 is reserved for padding so that's why we added 1\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PYLR_W62b3lm",
   "metadata": {
    "id": "PYLR_W62b3lm"
   },
   "source": [
    "**Next, we need to create sequences of words to fit the model with one word as input and one word as output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858f3ef5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "858f3ef5",
    "outputId": "081afb86-cef0-4f9a-aeb0-f3009d000afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209, 1974, 1, 444, 990]\n",
      "4413\n"
     ]
    }
   ],
   "source": [
    "# create word -> word sequences\n",
    "WORD_LENGTH = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(1, len(encoded_data) - WORD_LENGTH):\n",
    "    prev_words.append(encoded_data[i:i + WORD_LENGTH])\n",
    "    next_words.append(encoded_data[i + WORD_LENGTH])\n",
    "print(prev_words[0])\n",
    "print(next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "uiJwfjRM1WYf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiJwfjRM1WYf",
    "outputId": "0f0818de-4d88-46a2-b574-05bd5248a59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 64475\n"
     ]
    }
   ],
   "source": [
    "print('Total Sequences: %d' % len(prev_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "MNb-LdgdcqSZ",
   "metadata": {
    "id": "MNb-LdgdcqSZ"
   },
   "outputs": [],
   "source": [
    "# list(len(prev_words)[:5]) # [input, output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kMClupvlcdWq",
   "metadata": {
    "id": "kMClupvlcdWq"
   },
   "source": [
    "\n",
    "\n",
    "**We can then split the sequences into input (X) and output elements (y)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0fb1be0",
   "metadata": {
    "id": "f0fb1be0"
   },
   "outputs": [],
   "source": [
    "# split into X and y elements\n",
    "X = prev_words\n",
    "X = np.array(X)\n",
    "Y = next_words\n",
    "Y = np.array(Y)\n",
    "\n",
    "# X = np.zeros((len(prev_words), WORD_LENGTH, vocab_size), dtype=bool)\n",
    "# Y = np.zeros((len(next_words), vocab_size), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f323b68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f323b68",
    "outputId": "73f8a8cd-1298-49d6-810a-6f761e07d1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 209 1974    1  444  990]\n",
      " [1974    1  444  990 4413]\n",
      " [   1  444  990 4413 2675]\n",
      " [ 444  990 4413 2675  106]\n",
      " [ 990 4413 2675  106   21]]\n",
      "[4413 2675  106   21 4414]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d961d",
   "metadata": {
    "id": "101d961d"
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "Y = to_categorical(Y, num_classes=vocab_size)\n",
    "# define model\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ALNxgolmIFBD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALNxgolmIFBD",
    "outputId": "2fb2c8a3-ff8d-486e-efdd-6d73ea69d674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64475, 17323)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9-SgDZVKd_IL",
   "metadata": {
    "id": "9-SgDZVKd_IL"
   },
   "source": [
    "**Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b459da0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b459da0b",
    "outputId": "f688e5bf-e3e2-4e51-dd78-83982df6c178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 10)             173230    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                5504      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 17323)             571659    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750,393\n",
      "Trainable params: 750,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1)) # original: 5\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F1eNfS9cebdM",
   "metadata": {
    "id": "F1eNfS9cebdM"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Pjty_axoePeu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pjty_axoePeu",
    "outputId": "6ab68fe8-b418-473e-8863-440f6983ffe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 5).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 5).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015/2015 [==============================] - 26s 12ms/step - loss: 8.4516 - accuracy: 0.0295\n",
      "Epoch 2/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 7.8987 - accuracy: 0.0395\n",
      "Epoch 3/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 7.6717 - accuracy: 0.0433\n",
      "Epoch 4/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 7.4494 - accuracy: 0.0539\n",
      "Epoch 5/20\n",
      "2015/2015 [==============================] - 20s 10ms/step - loss: 7.2130 - accuracy: 0.0653\n",
      "Epoch 6/20\n",
      "2015/2015 [==============================] - 18s 9ms/step - loss: 6.9556 - accuracy: 0.0769\n",
      "Epoch 7/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 6.7032 - accuracy: 0.0865\n",
      "Epoch 8/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 6.4737 - accuracy: 0.0955\n",
      "Epoch 9/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 6.2582 - accuracy: 0.1040\n",
      "Epoch 10/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 6.0546 - accuracy: 0.1125\n",
      "Epoch 11/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 5.8589 - accuracy: 0.1212\n",
      "Epoch 12/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 5.6636 - accuracy: 0.1312\n",
      "Epoch 13/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 5.4739 - accuracy: 0.1416\n",
      "Epoch 14/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 5.3016 - accuracy: 0.1532\n",
      "Epoch 15/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 5.1415 - accuracy: 0.1650\n",
      "Epoch 16/20\n",
      "2015/2015 [==============================] - 18s 9ms/step - loss: 4.9906 - accuracy: 0.1770\n",
      "Epoch 17/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 4.8465 - accuracy: 0.1915\n",
      "Epoch 18/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 4.7105 - accuracy: 0.2042\n",
      "Epoch 19/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 4.5793 - accuracy: 0.2182\n",
      "Epoch 20/20\n",
      "2015/2015 [==============================] - 19s 9ms/step - loss: 4.4532 - accuracy: 0.2347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f77da250220>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "\n",
    "# compile network\n",
    "#### since labels are INTEGERS, we need to changed from loss='categorical_crossentropy'!!!\n",
    "#### If you want to provide labels using one-hot representation, please use CategoricalCrossentropy loss.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # optimizer ='adam'\n",
    "model.fit(X, Y, epochs=20)\n",
    "\n",
    "## Alternative versions\n",
    "# history = model.fit(X, Y, validation_split=0.05, batch_size=50, epochs=20, shuffle=True).history\n",
    "# history = model.fit(X, Y, validation_split=0.05, batch_size=50, epochs=20, shuffle=True).history\n",
    "# model.fit(X, Y, epochs=100)\n",
    "# model.fit(X, y, epochs=150, batch_size=64, callbacks=[checkpoint, reduce, tensorboard_Visualization])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QxgsBCrwtECi",
   "metadata": {
    "id": "QxgsBCrwtECi"
   },
   "source": [
    "**Save trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "A2ioJcaGtEN4",
   "metadata": {
    "id": "A2ioJcaGtEN4"
   },
   "outputs": [],
   "source": [
    "# After successful training, we will save the trained model and just load it back as needed.\n",
    "model.save('keras_next_word_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sI9KkPwTL3ee",
   "metadata": {
    "id": "sI9KkPwTL3ee"
   },
   "outputs": [],
   "source": [
    "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
    "model = load_model('keras_next_word_model.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XsrX16ketfZq",
   "metadata": {
    "id": "XsrX16ketfZq"
   },
   "source": [
    "**Prediction**\n",
    "Using saved model:\n",
    "- we input the sample as a feature vector\n",
    "- we convert the input string to a single feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4UPDwpgBtfkF",
   "metadata": {
    "id": "4UPDwpgBtfkF"
   },
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, WORD_LENGTH, vocab_size))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x\n",
    "prepare_input(\"HOSPITAL CORP SAYS IT RECEIVED 47 DLR A SHARE OFFER FROM INVESTOR GROUP\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fmfAeTHUt5aL",
   "metadata": {
    "id": "fmfAeTHUt5aL"
   },
   "outputs": [],
   "source": [
    "# To choose the best possible \"n\" words after the prediction from the model ...\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r75h3atZuDxS",
   "metadata": {
    "id": "r75h3atZuDxS"
   },
   "outputs": [],
   "source": [
    "# Use the function predict_completions to predict and return the list of \"n\" predicted words.\n",
    "def predict_completions(text, n=3):\n",
    "    if text == \"\":\n",
    "        return(\"0\")\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [unique_words[idx] for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cv5GjUyDuaNp",
   "metadata": {
    "id": "Cv5GjUyDuaNp"
   },
   "outputs": [],
   "source": [
    "# We use tokenizer.tokenize fo removing the punctuations and also we choose 5 first words because our predicts base on 5 previous words.\n",
    "\n",
    "q =  \"GILLETTE CANADA ISSUES 70 MLN STG BOND\"\n",
    "\n",
    "## 20 EXAMPLES FOR EVALUATION:\n",
    "\"\"\"\n",
    "'AMES DEPARTMENT STORE <ADD> MARCH SALES UP'\n",
    "'ISRAELI HELICOPTERS RAID SOUTH LEBANON - RADIO'\n",
    "'GILLETTE CANADA ISSUES 70 MLN STG BOND'\n",
    "'DIGITAL COMMUNICATIONS <DCAI> SELLS SWITCHES'\n",
    "'ITALIAN TREASURY BILL OFFER MEETS MIXED DEMAND'\n",
    "'WESTLAND TO CUT A THIRD OF HELICOPTER WORKFORCE'\n",
    "'USDA DETAILS FREE GRAIN STOCKS UNDER LOAN'\n",
    "'FED SAYS U.S. DISCOUNT WINDOW BORROWINGS 361 MLN DLRS IN APRIL 8 WEEK'\n",
    "'HOSPITAL CORP SAYS IT RECEIVED 47 DLR A SHARE OFFER FROM INVESTOR GROUP'\n",
    "'FED SEEN BUYING DOLLARS FOR YEN IN OPEN MARKET'\n",
    "'DOLLAR ENDS LOWER IN LACKLUSTRE FRANKFURT'\n",
    "'HEALTH AND REHABILITATION <HRP> INITIAL PAYOUT'\n",
    "'SUPERMARKETS GENERAL <SGL> FIVE WEEK SALES'\n",
    "'SEKISUI CHEMICAL ISSUES EQUITY WARRANT EUROBOND'\n",
    "'WEST GERMAN BEET PLANTINGS DELAYED THREE WEEKS'\n",
    "'BURMAH OIL PROSPECTS REMAIN FAVOURABLE'\n",
    "'PARKER DRILLING CO <PKD> 2ND QTR FEB 28 LOSS'\n",
    "'TURKEY CALLS FOR DIALOGUE TO SOLVE DISPUTE'\n",
    "'INVESTMENT TECHNOLOGIES <IVES> IN REBATE PACT'\n",
    "'ENTOURAGE <ENTG> HAS FIRST QUARTER LOSS'\n",
    "\"\"\"\n",
    "\n",
    "print(\"correct sentence: \",q)\n",
    "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
    "print(\"Sequence: \",seq)\n",
    "print(\"next possible words: \", predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H41rOg1XpXUl",
   "metadata": {
    "id": "H41rOg1XpXUl"
   },
   "source": [
    "**Creating a Prediction script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jVlQUV23pa6X",
   "metadata": {
    "id": "jVlQUV23pa6X"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model and tokenizer\n",
    "\n",
    "model = history\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "        In this function we are using the tokenizer and models trained\n",
    "        and we are creating the sequence of the text entered and then\n",
    "        using our model to predict and return the the predicted word.\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in range(3):\n",
    "        sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "        sequence = np.array(sequence)\n",
    "        \n",
    "        preds = model.predict_classes(sequence)\n",
    "#         print(preds)\n",
    "        predicted_word = \"\"\n",
    "        \n",
    "        for key, value in tokenizer.word_index.items():\n",
    "            if value == preds:\n",
    "                predicted_word = key\n",
    "                break\n",
    "        \n",
    "        print(predicted_word)\n",
    "        return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LxZ-ZlCkpgZ0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxZ-ZlCkpgZ0",
    "outputId": "0c39010f-4520-4860-a51a-3a940d7c23d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your line: ilona\n",
      "Enter your line: ISRAELI HELICOPTERS\n",
      "Enter your line: GILLETTE CANADA ISSUES\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    We are testing our model and we will run the model\n",
    "    until the user decides to stop the script.\n",
    "    While the script is running we try and check if \n",
    "    the prediction can be made on the text. If no\n",
    "    prediction can be made we just continue.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# text1 = \"at the dull\"\n",
    "# text2 = \"collection of textile\"\n",
    "# text3 = \"what a strenuous\"\n",
    "# text4 = \"stop the script\"\n",
    "\n",
    "while(True):\n",
    "\n",
    "    text = input(\"Enter your line: \")\n",
    "    \n",
    "    if text == \"stop the script\":\n",
    "        print(\"Ending The Program.....\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            text = text.split(\" \")\n",
    "            text = text[-1]\n",
    "\n",
    "            text = ''.join(text)\n",
    "            Predict_Next_Words(model, tokenizer, text)\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
