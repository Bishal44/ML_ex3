{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50eb1355",
   "metadata": {
    "id": "50eb1355"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 11:11:11.168227: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-24 11:11:11.331623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-24 11:11:11.331645: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-24 11:11:12.362057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-24 11:11:12.362295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-24 11:11:12.362317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nXwmMiUHVmN1",
   "metadata": {
    "id": "nXwmMiUHVmN1"
   },
   "source": [
    "**Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f4c486",
   "metadata": {
    "id": "b0f4c486"
   },
   "outputs": [],
   "source": [
    "name=\"LSTM 64\"\n",
    "documents = []\n",
    "for file in os.listdir(\"reuters_sample/\"): # original: \"reuters_data/\"\n",
    "    if file.endswith('.sgm'): # it is important for GoogleColab\n",
    "        filename = os.path.join(\"reuters_sample\", file) # original: \"reuters_data\"\n",
    "        f = open(filename, 'r', encoding='utf-8', errors='ignore')\n",
    "        dataFile = f.read().lower()\n",
    "        \n",
    "        soup = BeautifulSoup(dataFile, 'html.parser')\n",
    "\n",
    "        ## get all 'topic'\n",
    "        # topics = {topic.name for topic in soup.find_all()}\n",
    "  \n",
    "        ## iterate all 'topic'\n",
    "        # for topic in topics:\n",
    "          \n",
    "        ## find all element of 'topic'\n",
    "          # for i in soup.find_all('topic'):\n",
    "  \n",
    "        ## if tag has attribute of class\n",
    "            # if i.has_attr('trade'):\n",
    "  \n",
    "# We have selected the following 20 'TOPICS' out of 135:\n",
    "# that we want to use for our prediction exercise: 1.) \"trade\" 2.) \"earn\" 3.) \"grain\" 4.) \"money-fx\" 5.) \n",
    "# \"coffee\" 6.) \"gold\" 7.) \"acq\" 8.) \"wheat\" 9.) \"veg-oil\" 10.) \"nat-gas\" 11.) \"cooper\" 12.) \"ship\" 13.) \n",
    "# \"dlr\" 14.) \"crude\" 15.) \"interest\" 16.) \"meal-feed\" 17.) \"alum\" 18.) \"money-supply\" 19.) \"cocoa\" 20.) \"livestock\"\n",
    "        contents = soup.findAll('title')\n",
    "        \n",
    "        for content in contents:\n",
    "            documents.append(content.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "jwFHnhJ6YrPG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwFHnhJ6YrPG",
    "outputId": "d769a4f3-c6cf-427b-a14c-8aff14712298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 6966\n"
     ]
    }
   ],
   "source": [
    "print('Number of documents: {}'.format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "BwkB00Xzx-vT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwkB00Xzx-vT",
    "outputId": "96174c3f-7547-410f-e863-1e685dd209ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 6731\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated strings from the list of strings\n",
    "documents = [i for n, i in enumerate(documents) if i not in documents[:n]]\n",
    "\n",
    "print('Number of documents: {}'.format(len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9549e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f9549e3",
    "outputId": "34adf071-e76d-4a8a-da33-599a658dc082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inco sees no major impact from dow removal',\n",
       " 'former empire of carolina <emp> exec sentenced',\n",
       " 'doctors find link between aids, smallpox virus',\n",
       " 'birth control pills help prevent cancer - study',\n",
       " 'u.s. economic data key to debt futures outlook',\n",
       " 'u.s. \"action program\" for sub-saharan africa',\n",
       " 'unusual texas instruments <txn> preferred priced',\n",
       " 'clark says he expects u.s. action on acid rain',\n",
       " 'ford motor <f> distributes profit sharing',\n",
       " 'jamaica puts cap on borrowing']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fRsdiodgY4er",
   "metadata": {
    "id": "fRsdiodgY4er"
   },
   "source": [
    "**Join the documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5894ab",
   "metadata": {
    "id": "9e5894ab"
   },
   "outputs": [],
   "source": [
    "data = \"\"\n",
    "for d in documents:\n",
    "    data += d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a635c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3a635c4",
    "outputId": "2f6d665d-70bb-408a-ead2-2c2cf4bc68ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 347403\n"
     ]
    }
   ],
   "source": [
    "print('Number of data: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffe6795",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ffe6795",
    "outputId": "5cd35f61-cdbd-4e69-9b9c-57b0e2a101e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 346768\n",
      "inco sees no major impact from dow removalformer empire of carolina <emp> exec sentenceddoctors find\n"
     ]
    }
   ],
   "source": [
    "# improve punctuation\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "print('Number of data: {}'.format(len(data)))\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CNRiSJsMtwQu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNRiSJsMtwQu",
    "outputId": "6041d359-b0ae-4595-b68e-1b311d10f968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inco sees no major impact from dow removalformer empire of carolina  emp  exec sentenceddoctors find\n"
     ]
    }
   ],
   "source": [
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "data = data.translate(translator)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225b3c6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "225b3c6b",
    "outputId": "1a2ff1ab-a9ae-4344-d847-44f658e0b0e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1644, 19, 81, 366, 1094]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded_data = tokenizer.texts_to_sequences([data])[0]\n",
    "print(len(encoded_data))\n",
    "encoded_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff5b658",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cff5b658",
    "outputId": "c03f23da-60ed-4603-cbea-8aff102dcbe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 14407\n"
     ]
    }
   ],
   "source": [
    "# determine the vocabulary size\n",
    "# unique_words = tokenizer.word_index\n",
    "unique_words = np.unique(encoded_data)\n",
    "vocab_size = len(unique_words) + 1  # 0 is reserved for padding so that's why we added 1\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PYLR_W62b3lm",
   "metadata": {
    "id": "PYLR_W62b3lm"
   },
   "source": [
    "**Next, we need to create sequences of words to fit the model with one word as input and one word as output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858f3ef5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "858f3ef5",
    "outputId": "081afb86-cef0-4f9a-aeb0-f3009d000afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 81, 366, 1094, 46]\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "# create word -> word sequences\n",
    "WORD_LENGTH = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(1, len(encoded_data) - WORD_LENGTH):\n",
    "    prev_words.append(encoded_data[i:i + WORD_LENGTH])\n",
    "    next_words.append(encoded_data[i + WORD_LENGTH])\n",
    "print(prev_words[0])\n",
    "print(next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "uiJwfjRM1WYf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiJwfjRM1WYf",
    "outputId": "0f0818de-4d88-46a2-b574-05bd5248a59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 51494\n"
     ]
    }
   ],
   "source": [
    "print('Total Sequences: %d' % len(prev_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "MNb-LdgdcqSZ",
   "metadata": {
    "id": "MNb-LdgdcqSZ"
   },
   "outputs": [],
   "source": [
    "# list(len(prev_words)[:5]) # [input, output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kMClupvlcdWq",
   "metadata": {
    "id": "kMClupvlcdWq"
   },
   "source": [
    "\n",
    "\n",
    "**We can then split the sequences into input (X) and output elements (y)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0fb1be0",
   "metadata": {
    "id": "f0fb1be0"
   },
   "outputs": [],
   "source": [
    "# split into X and y elements\n",
    "X = prev_words\n",
    "X = np.array(X)\n",
    "Y = next_words\n",
    "Y = np.array(Y)\n",
    "\n",
    "# X = np.zeros((len(prev_words), WORD_LENGTH, vocab_size), dtype=bool)\n",
    "# Y = np.zeros((len(next_words), vocab_size), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f323b68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f323b68",
    "outputId": "73f8a8cd-1298-49d6-810a-6f761e07d1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  19   81  366 1094   46]\n",
      " [  81  366 1094   46  470]\n",
      " [ 366 1094   46  470 3706]\n",
      " [1094   46  470 3706 3707]\n",
      " [  46  470 3706 3707    8]]\n",
      "[ 470 3706 3707    8 1645]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])\n",
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "101d961d",
   "metadata": {
    "id": "101d961d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "Y = to_categorical(Y, num_classes=vocab_size)\n",
    "# define model\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ALNxgolmIFBD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALNxgolmIFBD",
    "outputId": "2fb2c8a3-ff8d-486e-efdd-6d73ea69d674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51494, 14407)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9-SgDZVKd_IL",
   "metadata": {
    "id": "9-SgDZVKd_IL"
   },
   "source": [
    "**Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b459da0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b459da0b",
    "outputId": "f688e5bf-e3e2-4e51-dd78-83982df6c178"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 22:43:29.156867: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 10)             144070    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                19200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14407)             936455    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,099,725\n",
      "Trainable params: 1,099,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 5, input_length=5)) # original: 5\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F1eNfS9cebdM",
   "metadata": {
    "id": "F1eNfS9cebdM"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Pjty_axoePeu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pjty_axoePeu",
    "outputId": "6ab68fe8-b418-473e-8863-440f6983ffe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 5).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 5).\n",
      "1610/1610 [==============================] - 41s 22ms/step - loss: 8.3509 - accuracy: 0.0310\n",
      "Epoch 2/20\n",
      "1610/1610 [==============================] - 26s 16ms/step - loss: 7.7608 - accuracy: 0.0428\n",
      "Epoch 3/20\n",
      "1610/1610 [==============================] - 37s 23ms/step - loss: 7.4973 - accuracy: 0.0541\n",
      "Epoch 4/20\n",
      "1610/1610 [==============================] - 50s 31ms/step - loss: 7.2161 - accuracy: 0.0702\n",
      "Epoch 5/20\n",
      "1610/1610 [==============================] - 47s 29ms/step - loss: 6.9066 - accuracy: 0.0845\n",
      "Epoch 6/20\n",
      "1610/1610 [==============================] - 47s 29ms/step - loss: 6.5791 - accuracy: 0.0964\n",
      "Epoch 7/20\n",
      "1610/1610 [==============================] - 46s 29ms/step - loss: 6.2337 - accuracy: 0.1083\n",
      "Epoch 8/20\n",
      "1610/1610 [==============================] - 44s 28ms/step - loss: 5.9019 - accuracy: 0.1195\n",
      "Epoch 9/20\n",
      "1610/1610 [==============================] - 45s 28ms/step - loss: 5.5890 - accuracy: 0.1327\n",
      "Epoch 10/20\n",
      "1610/1610 [==============================] - 44s 27ms/step - loss: 5.3016 - accuracy: 0.1464\n",
      "Epoch 11/20\n",
      "1610/1610 [==============================] - 44s 28ms/step - loss: 5.0343 - accuracy: 0.1633\n",
      "Epoch 12/20\n",
      "1610/1610 [==============================] - 48s 30ms/step - loss: 4.7783 - accuracy: 0.1832\n",
      "Epoch 13/20\n",
      "1610/1610 [==============================] - 45s 28ms/step - loss: 4.5395 - accuracy: 0.2098\n",
      "Epoch 14/20\n",
      "1610/1610 [==============================] - 57s 35ms/step - loss: 4.3132 - accuracy: 0.2387\n",
      "Epoch 15/20\n",
      "1610/1610 [==============================] - 60s 37ms/step - loss: 4.0983 - accuracy: 0.2713\n",
      "Epoch 16/20\n",
      "1610/1610 [==============================] - 56s 35ms/step - loss: 3.8973 - accuracy: 0.3067\n",
      "Epoch 17/20\n",
      "1610/1610 [==============================] - 42s 26ms/step - loss: 3.7055 - accuracy: 0.3391\n",
      "Epoch 18/20\n",
      "1610/1610 [==============================] - 45s 28ms/step - loss: 3.5198 - accuracy: 0.3705\n",
      "Epoch 19/20\n",
      "1610/1610 [==============================] - 44s 27ms/step - loss: 3.3442 - accuracy: 0.4012\n",
      "Epoch 20/20\n",
      "1610/1610 [==============================] - 42s 26ms/step - loss: 3.1784 - accuracy: 0.4316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa83fb6c670>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "\n",
    "# compile network\n",
    "#### since labels are INTEGERS, we need to changed from loss='categorical_crossentropy'!!!\n",
    "#### If you want to provide labels using one-hot representation, please use CategoricalCrossentropy loss.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # optimizer ='adam'\n",
    "history =model.fit(X, Y, epochs=20).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After successful training, we will save the trained model and just load it back as needed.\n",
    "model.save('keras_next_word_model'+str(name)+'.h5')\n",
    "pickle.dump(history, open('history'+str(name)+'.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41742bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading back the saved weights and history\n",
    "\n",
    "model = load_model('keras_next_word_model'+str(name)+'.h5')\n",
    "history = pickle.load(open('history'+str(name)+'.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy of '+str(name))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc= 'upper left')\n",
    "\n",
    "plt.savefig(\"01.Accuracy\"+str(name)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss of ' +str(name))\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc= 'upper left')\n",
    "\n",
    "plt.savefig(\"02.Loss\"+str(name)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1961f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len=6\n",
    "seed_text = \"computer terminal systems <cpml> completes\"\n",
    "next_words = 2\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    #predicted = model.predict_classes(token_list, verbose=0)\n",
    "    predict_x=model.predict(token_list) \n",
    "    predicted=np.argmax(predict_x,axis=1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
