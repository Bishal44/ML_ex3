# ML_ex3

Filtering conditions - concerning the topics for Exercise 3:
- the topic description sounds clear and logical
- re-used provided codes (w/o the need to re-implement or extend an existing one)
- re-use provided input data/ pictures / texts
- re-use existing lecture materials
- relatively cleare descriptions about the expectations
- experience with the owner of Topic 3.3 (Reinforcement learning)


Shortlisted topics (á la Gábor) based on "prio"rities:

3.1.) Advanced topics Adversarial Machine Learn & privacy-preserving Machine Learning - Prio 2
-	3.1.1.4: Model Stealing / Extraction (A.Type.1)
-	3.1.1.5: Detection of Model Extraction
-	3.1.1.6: Watermarking ML/DL models (Type B)
-	3.1.1.7: Model Inversion Attack (Type A)
-	3.1.1.9: Backdoor/poisoning Attacks & defence
-	3.1.1.10: Model Evasion Attack
-	3.1.3.4.: k-anonymity and utility of anonymized datasets

3.2.) Deep Learning for Image/Text Classification - Prio 1
-	3.2.1: Image / Text classification - Feature Extraction & Shallow vs. Deep Learning
-	3.2.2: Image-to-image processing via Deep Learning (e.g. CNN-based Image upscaling)
-		- image deblurring
  
PLEASE FEEL FREE TO COMMENT OR NARROW IT FURTHER!
